{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path('/mnt/data_set/criteo_ctr')\n",
    "data = pd.read_csv(data_root/'sample.csv', delimiter='\\t', header=None, nrows=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 40)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>f54016b9</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>07b5194c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>c5c50484</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>9727dd16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>b04e4670</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>60f6221e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>43f13e8b</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>731c3655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8efede7f</td>\n",
       "      <td>3412118d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e587c466</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>3b183c5c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4392.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>74ef3502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6b3a5ca6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>9117a34a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>26b3c7a7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21c9516a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>b34f3128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   I1   I2    I3    I4      I5    I6    I7   I8     I9  ...       C17  \\\n",
       "0      0  1.0    1   5.0   0.0  1382.0   4.0  15.0  2.0  181.0  ...  e5ba7672   \n",
       "1      0  2.0    0  44.0   1.0   102.0   8.0   2.0  2.0    4.0  ...  07c540c4   \n",
       "2      0  2.0    0   1.0  14.0   767.0  89.0   4.0  2.0  245.0  ...  8efede7f   \n",
       "3      0  NaN  893   NaN   NaN  4392.0   NaN   0.0  0.0    0.0  ...  1e88c74f   \n",
       "4      0  3.0   -1   NaN   0.0     2.0   0.0   3.0  0.0    0.0  ...  1e88c74f   \n",
       "\n",
       "        C18       C19       C20       C21       C22       C23       C24  \\\n",
       "0  f54016b9  21ddcdc9  b1252a9d  07b5194c       NaN  3a171ecb  c5c50484   \n",
       "1  b04e4670  21ddcdc9  5840adea  60f6221e       NaN  3a171ecb  43f13e8b   \n",
       "2  3412118d       NaN       NaN  e587c466  ad3062eb  3a171ecb  3b183c5c   \n",
       "3  74ef3502       NaN       NaN  6b3a5ca6       NaN  3a171ecb  9117a34a   \n",
       "4  26b3c7a7       NaN       NaN  21c9516a       NaN  32c7478e  b34f3128   \n",
       "\n",
       "        C25       C26  \n",
       "0  e8b83407  9727dd16  \n",
       "1  e8b83407  731c3655  \n",
       "2       NaN       NaN  \n",
       "3       NaN       NaN  \n",
       "4       NaN       NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = ['label']\n",
    "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "name_list = label + dense_features + sparse_features\n",
    "data.columns = name_list\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义特征组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_feats: :['I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I12', 'I13']\n",
      "sparse_feats: ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26']\n"
     ]
    }
   ],
   "source": [
    "dense_feats = [f for f in name_list if f[0] == \"I\"]\n",
    "sparse_feats = [f for f in name_list if f[0] == \"C\"]\n",
    "print('dense_feats: :%s' %dense_feats)\n",
    "print('sparse_feats: %s'% sparse_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理dense特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dense_feats(data, feats):\n",
    "    d = data.copy()\n",
    "    d = d[feats].fillna(0.0)\n",
    "    for f in feats:\n",
    "        d[f] = d[f].apply(lambda x: np.log(x+1) if x > -1 else -1)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dense = process_dense_feats(data, dense_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理sparse特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sparse_feats(data, feats):\n",
    "    d = data.copy()\n",
    "    d = d[feats].fillna(\"-1\")\n",
    "    for f in feats:\n",
    "        label_encoder = LabelEncoder()\n",
    "        d[f] = label_encoder.fit_transform(d[f])\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sparse = process_sparse_feats(data, sparse_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>...</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.232010</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>5.204007</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>2422</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>1163</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9570</td>\n",
       "      <td>41</td>\n",
       "      <td>5604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>4.634729</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>1727</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>14512</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3233</td>\n",
       "      <td>41</td>\n",
       "      <td>4215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>6.643790</td>\n",
       "      <td>4.499810</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>5.505332</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34644</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.795706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.387768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15997</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>390</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>560</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>5553</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3818</td>\n",
       "      <td>12</td>\n",
       "      <td>4183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.061752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1727</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>14512</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3233</td>\n",
       "      <td>43</td>\n",
       "      <td>4215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>6.180017</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>1648</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>12138</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2271</td>\n",
       "      <td>2</td>\n",
       "      <td>8780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.968708</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>12.752360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32886</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.927254</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>9.159573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>882</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>2322</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9792</td>\n",
       "      <td>1</td>\n",
       "      <td>5699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             I1        I2        I3        I4         I5        I6        I7  \\\n",
       "0      0.693147  0.693147  1.791759  0.000000   7.232010  1.609438  2.772589   \n",
       "1      1.098612  0.000000  3.806662  0.693147   4.634729  2.197225  1.098612   \n",
       "2      1.098612  0.000000  0.693147  2.708050   6.643790  4.499810  1.609438   \n",
       "3      0.000000  6.795706  0.000000  0.000000   8.387768  0.000000  0.000000   \n",
       "4      1.386294 -1.000000  0.000000  0.000000   1.098612  0.000000  1.386294   \n",
       "...         ...       ...       ...       ...        ...       ...       ...   \n",
       "99995  0.693147  4.110874  3.637586  0.000000   0.693147  0.000000  1.609438   \n",
       "99996  0.000000  0.000000  2.564949  0.000000  12.061752  0.000000  0.000000   \n",
       "99997  2.397895  1.098612  0.693147  3.295837   6.180017  4.110874  2.397895   \n",
       "99998  0.000000  5.968708  3.784190  1.609438  12.752360  0.000000  0.000000   \n",
       "99999  0.000000 -1.000000  4.927254  2.995732   9.159573  0.000000  0.000000   \n",
       "\n",
       "             I8        I9       I10  ...   C18  C19  C20    C21  C22  C23  \\\n",
       "0      1.098612  5.204007  0.693147  ...  2422  150    3   1163    0    2   \n",
       "1      1.098612  1.609438  0.693147  ...  1727  150    1  14512    0    2   \n",
       "2      1.098612  5.505332  0.693147  ...   510    0    0  34644    6    2   \n",
       "3      0.000000  0.000000  0.000000  ...  1170    0    0  15997    0    2   \n",
       "4      0.000000  0.000000  0.693147  ...   390    0    0   5101    0    1   \n",
       "...         ...       ...       ...  ...   ...  ...  ...    ...  ...  ...   \n",
       "99995  0.000000  3.178054  0.693147  ...   560  150    3   5553    0    1   \n",
       "99996  1.386294  2.397895  0.000000  ...  1727  150    3  14512    0    1   \n",
       "99997  2.484907  4.110874  0.693147  ...  1648  150    2  12138    0    1   \n",
       "99998  1.609438  1.609438  0.000000  ...   302    0    0  32886    0    1   \n",
       "99999  3.135494  3.135494  0.000000  ...   882  150    1   2322    8    1   \n",
       "\n",
       "        C24  C25   C26  label  \n",
       "0      9570   41  5604      0  \n",
       "1      3233   41  4215      0  \n",
       "2      2818    0     0      0  \n",
       "3      6971    0     0      0  \n",
       "4      8663    0     0      0  \n",
       "...     ...  ...   ...    ...  \n",
       "99995  3818   12  4183      0  \n",
       "99996  3233   43  4215      1  \n",
       "99997  2271    2  8780      0  \n",
       "99998  6918    0     0      0  \n",
       "99999  9792    1  5699      0  \n",
       "\n",
       "[100000 rows x 40 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = pd.concat([data_dense, data_sparse], axis=1)\n",
    "total_data['label'] = data['label']\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.77337\n",
       "1    0.22663\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dense_inputs, test_dense_inputs, train_sparse_inputs, test_sparse_inputs, train_y, test_y = train_test_split(\n",
    "    data_dense.values, data_sparse.values, y.values, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 13), (70000, 26), (70000,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dense_inputs.shape, train_sparse_inputs.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 13), (30000, 26), (30000,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dense_inputs.shape, test_sparse_inputs.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  541   497 43870 25184   145    12  7623   257     3 10997  3799 41312\n",
      "  2796    26  5238 34617    10  2548  1303     4 38618    11    14 12335\n",
      "    51  9527]\n"
     ]
    }
   ],
   "source": [
    "category_dim = data_sparse.nunique().values\n",
    "print(category_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建与训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一阶特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dense特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(layers.Layer):\n",
    "    def __init__(self, category_dim=[]):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.dense = tf.keras.layers.Dense(1)\n",
    "        self.embeddings = []\n",
    "        for size in category_dim:\n",
    "            em = layers.Embedding(size+1, 1)\n",
    "            self.embeddings.append(em)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        if len(self.embeddings) > 0:\n",
    "            dense_inputs, sparse_inputs = inputs\n",
    "            embedding_outputs = []\n",
    "            for i in range(sparse_inputs.shape[1]):\n",
    "                x = sparse_inputs[:, i]\n",
    "                x = self.embeddings[i](x)\n",
    "                embedding_outputs.append(x)\n",
    "            \n",
    "            x = tf.concat(embedding_outputs, axis=1)\n",
    "            x = tf.concat([dense_inputs, x], axis=1)\n",
    "        else:\n",
    "            x = inputs\n",
    "        x = self.dense(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(layers.Layer):\n",
    "    def __init__(self, category_dim, embedding_dim=8):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = []\n",
    "        for size in category_dim:\n",
    "            em = layers.Embedding(size+1, embedding_dim)\n",
    "            self.embeddings.append(em)    \n",
    "\n",
    "    def call(self, sparse_inputs):\n",
    "        embedding_outputs = []\n",
    "        for i in range(sparse_inputs.shape[1]):\n",
    "            x = sparse_inputs[:, i]\n",
    "            x = self.embeddings[i](x)\n",
    "            embedding_outputs.append(x)\n",
    "\n",
    "        x = tf.stack(embedding_outputs, axis=1)  ## [batch, feat, embedding_dim]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FM 用于二阶特征交叉\n",
    "$$\\sum_{i=1}^n\\sum_{j=i+1}^n \\langle v_i, v_j \\rangle x_i x_j=\\frac{1}{2} \\sum_{f=1}^k[(\\sum_{i=1}^n V_{if})^2 - \\sum_{i=1}^n V_{if}^2]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMLayer(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(FMLayer, self).__init__()\n",
    "        # 只考虑sparse特征的二阶交叉\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        ## inputs is EmbeddingLayer's output\n",
    "        # 和的平方\n",
    "        x = inputs\n",
    "        s = tf.reduce_sum(x, axis=1)\n",
    "        sum_square = tf.multiply(s, s)\n",
    "        # 平方的和\n",
    "        square_sum = tf.reduce_sum(tf.multiply(x, x), axis=1)\n",
    "        # 相减再求和除以2\n",
    "        x = tf.reduce_sum(sum_square - square_sum, axis=1, keepdims=True) / 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(layers.Layer):\n",
    "    def __init__(self, kernels_size=[]):\n",
    "        super(DNN, self).__init__()\n",
    "        assert len(kernels_size) > 0\n",
    "        self.denses = []\n",
    "        self.dropouts = []\n",
    "        for size in kernels_size:\n",
    "            self.denses.append(layers.Dense(size, activation='relu'))\n",
    "        for i in range(len(kernels_size)-1):\n",
    "            self.dropouts.append(layers.Dropout(0.3))\n",
    "        self.dropouts.append(layers.Dropout(0.1))\n",
    "        self.output_layer = layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        dense_inputs, embedding_inputs = inputs  ## [batch, dense_feats], [batch, feat, embedding_dim]\n",
    "        x = layers.Flatten()(embedding_inputs)\n",
    "        x = tf.concat([dense_inputs, x], axis=1)\n",
    "        for dense, dropout in zip(self.denses, self.dropouts):\n",
    "            x = dense(x)\n",
    "            x = dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep(tf.keras.Model):\n",
    "    def __init__(self, category_dim, embedding_dim=8, dnn_layers=[8]):\n",
    "        super(WideAndDeep, self).__init__()\n",
    "        self.category_dim = category_dim\n",
    "        self.linear_layer = LinearLayer(category_dim)\n",
    "        self.em_layer = EmbeddingLayer(category_dim, embedding_dim)\n",
    "        self.dnn_layer = DNN(kernels_size=dnn_layers)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        dense_inputs, sparse_inputs = inputs\n",
    "        linear_output = self.linear_layer([dense_inputs, sparse_inputs])\n",
    "        em_output = self.em_layer(sparse_inputs)\n",
    "        dnn_output = self.dnn_layer([dense_inputs, em_output])\n",
    "        out = layers.Add()([linear_output, dnn_output])\n",
    "        out = layers.Activation('sigmoid')(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "log_dir = './logs'\n",
    "shutil.rmtree(log_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = TensorBoard(log_dir=log_dir,  # log 目录\n",
    "                 histogram_freq=0, \n",
    "                 write_graph=True,\n",
    "                 write_images=True,\n",
    "                 embeddings_freq=0, \n",
    "                 embeddings_layer_names=None, \n",
    "                 embeddings_metadata=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仅使用Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70000 samples, validate on 30000 samples\n",
      "Epoch 1/5\n",
      "70000/70000 [==============================] - 11s 151us/sample - loss: 0.4931 - auc: 0.6985 - val_loss: 0.4582 - val_auc: 0.7619\n",
      "Epoch 2/5\n",
      "70000/70000 [==============================] - 6s 89us/sample - loss: 0.4111 - auc: 0.8181 - val_loss: 0.4543 - val_auc: 0.7691\n",
      "Epoch 3/5\n",
      "70000/70000 [==============================] - 6s 85us/sample - loss: 0.3291 - auc: 0.8923 - val_loss: 0.4946 - val_auc: 0.7431\n",
      "Epoch 4/5\n",
      "70000/70000 [==============================] - 6s 90us/sample - loss: 0.2511 - auc: 0.9383 - val_loss: 0.5500 - val_auc: 0.7228\n",
      "Epoch 5/5\n",
      "70000/70000 [==============================] - 6s 89us/sample - loss: 0.2088 - auc: 0.9577 - val_loss: 0.6137 - val_auc: 0.7106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbab8671ed0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WideAndDeep(category_dim, embedding_dim=2, dnn_layers=[16, 8])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()])\n",
    "model.fit([train_dense_inputs, train_sparse_inputs], train_y, epochs=5, batch_size=64, \n",
    "         validation_data=([test_dense_inputs, test_sparse_inputs], test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仅使用FTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70000 samples, validate on 30000 samples\n",
      "Epoch 1/5\n",
      "70000/70000 [==============================] - 7s 96us/sample - loss: 0.5429 - auc_1: 0.5662 - val_loss: 0.5375 - val_auc_1: 0.5959\n",
      "Epoch 2/5\n",
      "70000/70000 [==============================] - 4s 55us/sample - loss: 0.5273 - auc_1: 0.6037 - val_loss: 0.5296 - val_auc_1: 0.6208\n",
      "Epoch 3/5\n",
      "70000/70000 [==============================] - 4s 57us/sample - loss: 0.5211 - auc_1: 0.6219 - val_loss: 0.5244 - val_auc_1: 0.6358\n",
      "Epoch 4/5\n",
      "70000/70000 [==============================] - 4s 60us/sample - loss: 0.5170 - auc_1: 0.6336 - val_loss: 0.5206 - val_auc_1: 0.6462\n",
      "Epoch 5/5\n",
      "70000/70000 [==============================] - 4s 64us/sample - loss: 0.5141 - auc_1: 0.6415 - val_loss: 0.5177 - val_auc_1: 0.6538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbaa42f6810>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WideAndDeep(category_dim, embedding_dim=2, dnn_layers=[16, 8])\n",
    "model.compile(optimizer='ftrl', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()])\n",
    "model.fit([train_dense_inputs, train_sparse_inputs], train_y, epochs=5, batch_size=64, \n",
    "         validation_data=([test_dense_inputs, test_sparse_inputs], test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wide部分使用ftrl，deep部分使用adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(name='bce')\n",
    "adam = tf.keras.optimizers.Adam()  ## use name or class\n",
    "ftrl = tf.keras.optimizers.Ftrl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_auc = tf.keras.metrics.AUC(name='train_auc')\n",
    "test_auc = tf.keras.metrics.AUC(name='test_auc')\n",
    "\n",
    "train_bce = tf.keras.metrics.BinaryCrossentropy(name='train_bce')\n",
    "test_bce = tf.keras.metrics.BinaryCrossentropy(name='test_bce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = WideAndDeep(category_dim, embedding_dim=2, dnn_layers=[16, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model2(x, training=True)\n",
    "        l = loss(y, pred)\n",
    "    grads = tape.gradient(l, model2.trainable_variables)\n",
    "    \n",
    "    linear_grads, linear_variables = [], []\n",
    "    dnn_grads, dnn_variables = [], []\n",
    "\n",
    "    for grad, variable in zip(grads, model2.trainable_variables):\n",
    "        if 'linear_layer' in variable.name:\n",
    "            linear_grads.append(grad)\n",
    "            linear_variables.append(variable)\n",
    "        else:\n",
    "            dnn_grads.append(grad)\n",
    "            dnn_variables.append(variable)\n",
    "    \n",
    "    ftrl.apply_gradients(zip(linear_grads, linear_variables))\n",
    "    adam.apply_gradients(zip(dnn_grads, dnn_variables))\n",
    "    \n",
    "    pred = tf.squeeze(pred, axis=1)\n",
    "    train_auc(y, pred)\n",
    "    train_bce(y, pred)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    pred = model2(x, training=False)\n",
    "    t_l = loss(y, pred)\n",
    "    pred = tf.squeeze(pred, axis=1)\n",
    "    test_auc(y, pred)\n",
    "    test_bce(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer wide_and_deep_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1, Loss: 0.5017977952957153, AUC: 0.6747088432312012, Test Loss: 0.4640750288963318, Test AUC: 0.7572975754737854\n",
      "Epoch 2, Loss: 0.42777374386787415, AUC: 0.7985280156135559, Test Loss: 0.4681999385356903, Test AUC: 0.755859375\n",
      "Epoch 3, Loss: 0.33143845200538635, AUC: 0.8908410668373108, Test Loss: 0.5349065065383911, Test AUC: 0.7248665690422058\n",
      "Epoch 4, Loss: 0.25959959626197815, AUC: 0.9352536797523499, Test Loss: 0.5827466249465942, Test AUC: 0.710716187953949\n",
      "Epoch 5, Loss: 0.21902045607566833, AUC: 0.9543431401252747, Test Loss: 0.6341908574104309, Test AUC: 0.7003298401832581\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "batch = 64\n",
    "template = 'Epoch {}, Loss: {}, AUC: {}, Test Loss: {}, Test AUC: {}'\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_auc.reset_states()\n",
    "    test_auc.reset_states()\n",
    "    \n",
    "    train_bce.reset_states()\n",
    "    test_bce.reset_states()\n",
    "    \n",
    "    for i in range(0, len(train_y)-batch+1, batch):\n",
    "        d_x, s_x, b_y = train_dense_inputs[i:i+batch], train_sparse_inputs[i:i+batch], train_y[i:i+batch]\n",
    "        train_step([d_x, s_x], b_y)\n",
    "    \n",
    "    for i in range(0, len(test_y)-batch+1, batch):\n",
    "        d_x, s_x, b_y = test_dense_inputs[i:i+batch], test_sparse_inputs[i:i+batch], test_y[i:i+batch]\n",
    "        test_step([d_x, s_x], b_y)\n",
    "\n",
    "    print(template.format(epoch+1, train_bce.result(), train_auc.result(), test_bce.result(), test_auc.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, 'deep_fm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wide_and_deep_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "linear_layer_1 (LinearLayer) multiple                  241404    \n",
      "_________________________________________________________________\n",
      "embedding_layer_1 (Embedding multiple                  482728    \n",
      "_________________________________________________________________\n",
      "dnn_1 (DNN)                  multiple                  1201      \n",
      "=================================================================\n",
      "Total params: 725,333\n",
      "Trainable params: 725,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: tensorboard: not found\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir ./logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_gpu",
   "language": "python",
   "name": "tf2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
